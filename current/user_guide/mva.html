

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Machine learning &mdash; HyperSpy 1.6.4 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/hyperspy.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/toggleprompt.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model fitting" href="model.html" />
    <link rel="prev" title="Data visualization" href="visualisation.html" />
 
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-25260850-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> HyperSpy
          

          
            
            <img src="../_static/hyperspy_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.6.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installing HyperSpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal.html">The Signal class</a></li>
<li class="toctree-l1"><a class="reference internal" href="interactive_operations_ROIs.html">Interactive Operations and Region of Interest (ROI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal1d.html">Signal1D Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal2d.html">Signal2D Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualisation.html">Data visualization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Machine learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#decomposition">Decomposition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#available-algorithms">Available algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#singular-value-decomposition-svd">Singular value decomposition (SVD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#principal-component-analysis-pca">Principal component analysis (PCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#poissonian-noise">Poissonian noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maximum-likelihood-principal-component-analysis-mlpca">Maximum likelihood principal component analysis (MLPCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robust-principal-component-analysis-rpca">Robust principal component analysis (RPCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#non-negative-matrix-factorization-nmf">Non-negative matrix factorization (NMF)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robust-non-negative-matrix-factorization-rnmf">Robust non-negative matrix factorization (RNMF)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-decomposition-algorithms">Custom decomposition algorithms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#blind-source-separation">Blind Source Separation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Available algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#orthomax">Orthomax</a></li>
<li class="toctree-l3"><a class="reference internal" href="#independent-component-analysis-ica">Independent component analysis (ICA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-bss-algorithms">Custom BSS algorithms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cluster-analysis">Cluster analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nomenclature">Nomenclature</a></li>
<li class="toctree-l3"><a class="reference internal" href="#clustering-functions-hyperspy">Clustering functions HyperSpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pre-processing">Pre-processing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cluster-signals">Cluster signals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clustering-with-user-defined-algorithms">Clustering with user defined algorithms</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#clustering-using-decomposition-results">Clustering using decomposition results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clustering-using-another-signal-as-source">Clustering using another signal as source</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#visualizing-results">Visualizing results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scree-plots">Scree plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decomposition-plots">Decomposition plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blind-source-separation-plots">Blind source separation plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="#clustering-plots">Clustering plots</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#obtaining-the-results-as-basesignal-instances">Obtaining the results as BaseSignal instances</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saving-and-loading-results">Saving and loading results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#saving-in-the-main-file">Saving in the main file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-to-an-external-file">Saving to an external file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-in-different-formats">Exporting in different formats</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Model fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="eels.html">Electron Energy Loss Spectroscopy</a></li>
<li class="toctree-l1"><a class="reference internal" href="eds.html">Energy-Dispersive X-ray Spectrometry (EDS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dielectric_function.html">Dielectric function tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="electron_holography.html">Electron Holography</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">Loading and saving data</a></li>
<li class="toctree-l1"><a class="reference internal" href="events.html">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="big_data.html">Working with big data</a></li>
<li class="toctree-l1"><a class="reference internal" href="metadata_structure.html">Metadata structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/git.html">Using Git and GitHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/testing.html">Running and writing tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/writing_docs.html">Writing documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/coding_style.html">Coding style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/lazy_computations.html">Tips for writing methods that work on lazy signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/speeding_up_code.html">Speeding up code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/writing_extensions.html">Writing packages that extend HyperSpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/useful_information.html">Useful information</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/modules.html">hyperspy</a></li>
</ul>
<p class="caption"><span class="caption-text">Credits and citation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../credits.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../citing.html">Citing HyperSpy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">HyperSpy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Machine learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/user_guide/mva.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="machine-learning">
<span id="ml-label"></span><h1>Machine learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>HyperSpy provides easy access to several “machine learning” algorithms that
can be useful when analysing multi-dimensional data. In particular,
decomposition algorithms, such as principal component analysis (PCA), or
blind source separation (BSS) algorithms, such as independent component
analysis (ICA), are available through the methods described in this section.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>HyperSpy will decompose a dataset, <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/>, into two new datasets:
one with the dimension of the signal space known as <strong>factors</strong> (<img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/>),
and the other with the dimension of the navigation space known as <strong>loadings</strong>
(<img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/>), such that <img class="math" src="../_images/math/f675f74826a6f83e288c9ae8f164cc8fa4343a57.png" alt="X = A B^T"/>.</p>
<p>For some of the algorithms listed below, the decomposition results in
an <cite>approximation</cite> of the dataset, i.e. <img class="math" src="../_images/math/22e42898fdde1552f0b0db9945ec87198ad6e0a2.png" alt="X \approx A B^T"/>.</p>
</div>
</div>
<div class="section" id="decomposition">
<span id="mva-decomposition"></span><h2>Decomposition<a class="headerlink" href="#decomposition" title="Permalink to this headline">¶</a></h2>
<p>Decomposition techniques are most commonly used as a means of noise
reduction (or <cite>denoising</cite>) and dimensionality reduction. To apply a
decomposition to your dataset, run the <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.decomposition" title="hyperspy.learn.mva.MVA.decomposition"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decomposition()</span></code></a>
method, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hyperspy.signals</span> <span class="kn">import</span> <span class="n">Signal1D</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">Signal1D</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load data from a file, then decompose</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;my_file.hspy&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The signal <code class="docutils literal notranslate"><span class="pre">s</span></code> must be multi-dimensional, <em>i.e.</em>
<code class="docutils literal notranslate"><span class="pre">s.axes_manager.navigation_size</span> <span class="pre">&gt;</span> <span class="pre">1</span></code></p>
</div>
<p>One of the most popular uses of <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.decomposition" title="hyperspy.learn.mva.MVA.decomposition"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decomposition()</span></code></a>
is data denoising. This is achieved by using a limited set of components
to make a model of the original dataset, omitting the less significant components that
ideally contain only noise.</p>
<p>To reconstruct your denoised or reduced model, run the
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.get_decomposition_model" title="hyperspy.learn.mva.MVA.get_decomposition_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_decomposition_model()</span></code></a> method. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use all components to reconstruct the model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">get_decomposition_model</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use first 3 components to reconstruct the model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">get_decomposition_model</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use components [0, 2] to reconstruct the model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">get_decomposition_model</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>Sometimes, it is useful to examine the residuals between your original data and
the decomposition model. You can easily calculate and display the residuals,
since <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.get_decomposition_model" title="hyperspy.learn.mva.MVA.get_decomposition_model"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_decomposition_model()</span></code></a> returns a new
object, which in the example above we have called <code class="docutils literal notranslate"><span class="pre">sc</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="n">sc</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<p>You can perform operations on this new object <code class="docutils literal notranslate"><span class="pre">sc</span></code> later.
It is a copy of the original <code class="docutils literal notranslate"><span class="pre">s</span></code> object, except that the data has
been replaced by the model constructed using the chosen components.</p>
<p>If you provide the <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code> argument, which takes an integer value,
the decomposition algorithm attempts to find the best approximation for the
dataset <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/> with only a limited set of factors <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> and loadings <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/>,
such that <img class="math" src="../_images/math/22e42898fdde1552f0b0db9945ec87198ad6e0a2.png" alt="X \approx A B^T"/>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>Some of the algorithms described below require <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code> to be provided.</p>
<div class="section" id="available-algorithms">
<h3>Available algorithms<a class="headerlink" href="#available-algorithms" title="Permalink to this headline">¶</a></h3>
<p>HyperSpy implements a number of decomposition algorithms via the <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> argument.
The table below lists the algorithms that are currently available, and includes
links to the appropriate documentation for more information on each one.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Choosing which algorithm to use is likely to depend heavily on the nature of your
dataset and the type of analysis you are trying to perform. We discuss some of the
reasons for choosing one algorithm over another below, but would encourage you to
do your own research as well. The <a class="reference external" href="https://scikit-learn.org/stable/modules/decomposition.html">scikit-learn documentation</a> is a
very good starting point.</p>
</div>
<span id="decomposition-table"></span><table class="docutils align-default" id="id6">
<caption><span class="caption-text">Available decomposition algorithms in HyperSpy</span><a class="headerlink" href="#id6" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 29%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Algorithm</p></th>
<th class="head"><p>Method</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>“SVD” (default)</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.svd_pca.html#hyperspy.learn.svd_pca.svd_pca" title="hyperspy.learn.svd_pca.svd_pca"><code class="xref py py-func docutils literal notranslate"><span class="pre">svd_pca()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>“MLPCA”</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.mlpca.html#hyperspy.learn.mlpca.mlpca" title="hyperspy.learn.mlpca.mlpca"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlpca()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p>“sklearn_pca”</p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.PCA</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>“NMF”</p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.NMF</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p>“sparse_pca”</p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html#sklearn.decomposition.SparsePCA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.SparsePCA</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>“mini_batch_sparse_pca”</p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchSparsePCA.html#sklearn.decomposition.MiniBatchSparsePCA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.MiniBatchSparsePCA</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p>“RPCA”</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.rpca.html#hyperspy.learn.rpca.rpca_godec" title="hyperspy.learn.rpca.rpca_godec"><code class="xref py py-func docutils literal notranslate"><span class="pre">rpca_godec()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>“ORPCA”</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.rpca.html#hyperspy.learn.rpca.ORPCA" title="hyperspy.learn.rpca.ORPCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">ORPCA</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p>“ORNMF”</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.ornmf.html#hyperspy.learn.ornmf.ORNMF" title="hyperspy.learn.ornmf.ORNMF"><code class="xref py py-class docutils literal notranslate"><span class="pre">ORNMF</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>custom object</p></td>
<td><p>An object implementing  <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and  <code class="docutils literal notranslate"><span class="pre">transform()</span></code> methods</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="singular-value-decomposition-svd">
<span id="mva-svd"></span><h3>Singular value decomposition (SVD)<a class="headerlink" href="#singular-value-decomposition-svd" title="Permalink to this headline">¶</a></h3>
<p>The default algorithm in HyperSpy is <code class="docutils literal notranslate"><span class="pre">&quot;SVD&quot;</span></code>, which uses an approach called
“singular value decomposition” to decompose the data in the form
<img class="math" src="../_images/math/78d3f697c5bf46bb2f905987c87fd56d77ada9ac.png" alt="X = U \Sigma V^T"/>. The factors are given by <img class="math" src="../_images/math/b953581b68938e930c0764b251954045a0f1cd67.png" alt="U \Sigma"/>, and the
loadings are given by <img class="math" src="../_images/math/87bf9fc412cc4fdc23af6f48bda75f7a9ebcb38d.png" alt="V^T"/>. For more information, please read the method
documentation for <a class="reference internal" href="../api/hyperspy.learn.svd_pca.html#hyperspy.learn.svd_pca.svd_pca" title="hyperspy.learn.svd_pca.svd_pca"><code class="xref py py-func docutils literal notranslate"><span class="pre">svd_pca()</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hyperspy.signals</span> <span class="kn">import</span> <span class="n">Signal1D</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">Signal1D</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some fields, including electron microscopy, this approach of applying an SVD
directly to the data <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/> is often called PCA <a class="reference internal" href="#mva-pca"><span class="std std-ref">(see below)</span></a>.</p>
<p>However, in the classical definition of PCA, the SVD should be applied to data that has
first been “centered” by subtracting the mean, i.e. <img class="math" src="../_images/math/3c466bd1c7969805c9a52226f59837b0eb779191.png" alt="\mathrm{SVD}(X - \bar X)"/>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;SVD&quot;</span></code> algorithm in HyperSpy <strong>does not</strong> apply this
centering step by default. As a result, you may observe differences between
the output of the <code class="docutils literal notranslate"><span class="pre">&quot;SVD&quot;</span></code> algorithm and, for example,
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.PCA</span></code></a>, which <strong>does</strong> apply centering.</p>
</div>
</div>
<div class="section" id="principal-component-analysis-pca">
<span id="mva-pca"></span><h3>Principal component analysis (PCA)<a class="headerlink" href="#principal-component-analysis-pca" title="Permalink to this headline">¶</a></h3>
<p>One of the most popular decomposition methods is <a class="reference external" href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a> (PCA).
To perform PCA on your dataset, run the <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.decomposition" title="hyperspy.learn.mva.MVA.decomposition"><code class="xref py py-meth docutils literal notranslate"><span class="pre">decomposition()</span></code></a>
method with any of following arguments.</p>
<p>If you have <a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> installed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sklearn_pca&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also turn on centering with the default <code class="docutils literal notranslate"><span class="pre">&quot;SVD&quot;</span></code> algorithm via
the <code class="docutils literal notranslate"><span class="pre">&quot;centre&quot;</span></code> argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Subtract the mean along the navigation axis</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SVD&quot;</span><span class="p">,</span> <span class="n">centre</span><span class="o">=</span><span class="s2">&quot;navigation&quot;</span><span class="p">)</span>

<span class="c1"># Subtract the mean along the signal axis</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SVD&quot;</span><span class="p">,</span> <span class="n">centre</span><span class="o">=</span><span class="s2">&quot;signal&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also use <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.PCA</span></code></a> directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="n">PCA</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="section" id="poissonian-noise">
<span id="poissonian-noise-label"></span><h3>Poissonian noise<a class="headerlink" href="#poissonian-noise" title="Permalink to this headline">¶</a></h3>
<p>Most of the standard decomposition algorithms assume that the noise of the data
follows a Gaussian distribution (also known as “homoskedastic noise”).
In cases where your data is instead corrupted by Poisson noise, HyperSpy
can “normalize” the data by performing a scaling operation, which can greatly
enhance the result. More details about the normalization procedure can be
found in <a class="reference internal" href="bibliography.html#keenan2004"><span class="std std-ref">[Keenan2004]</span></a>.</p>
<p>To apply Poissonian noise normalization to your data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">normalize_poissonian_noise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Because it is the first argument we could have simply written:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Poisson noise normalization cannot be used in combination with data
centering using the <code class="docutils literal notranslate"><span class="pre">'centre'</span></code> argument. Attempting to do so will
raise an error.</p>
</div>
</div>
<div class="section" id="maximum-likelihood-principal-component-analysis-mlpca">
<span id="mva-mlpca"></span><h3>Maximum likelihood principal component analysis (MLPCA)<a class="headerlink" href="#maximum-likelihood-principal-component-analysis-mlpca" title="Permalink to this headline">¶</a></h3>
<p>Instead of applying Poisson noise normalization to your data, you can instead
use an approach known as Maximum Likelihood PCA (MLPCA), which provides a more
robust statistical treatment of non-Gaussian “heteroskedastic noise”.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;MLPCA&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, please read the method documentation for <a class="reference internal" href="../api/hyperspy.learn.mlpca.html#hyperspy.learn.mlpca.mlpca" title="hyperspy.learn.mlpca.mlpca"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlpca()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You must set the <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code> when using MLPCA.</p>
</div>
</div>
<div class="section" id="robust-principal-component-analysis-rpca">
<span id="mva-rpca"></span><h3>Robust principal component analysis (RPCA)<a class="headerlink" href="#robust-principal-component-analysis-rpca" title="Permalink to this headline">¶</a></h3>
<p>PCA is known to be very sensitive to the presence of outliers in data. These
outliers can be the result of missing or dead pixels, X-ray spikes, or very
low count data. If one assumes a dataset, <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/>, to consist of a low-rank
component <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/> corrupted by a sparse error component <img class="math" src="../_images/math/b988975be41fd13b4d091c10202ba19374643586.png" alt="S"/>, such that
<img class="math" src="../_images/math/b9c5af8b03fdcfbb0ffb5e42d9fabe1524fd3fe1.png" alt="X=L+S"/>, then Robust PCA (RPCA) can be used to recover the low-rank
component for subsequent processing <a class="reference internal" href="bibliography.html#candes2011"><span class="std std-ref">[Candes2011]</span></a>.</p>
<div class="figure align-center" id="id7">
<a class="reference internal image-reference" href="../_images/rpca_schematic.png"><img alt="../_images/rpca_schematic.png" src="../_images/rpca_schematic.png" style="width: 425px;" /></a>
<p class="caption"><span class="caption-text">Schematic diagram of the robust PCA problem, which combines a low-rank matrix
with sparse errors. Robust PCA aims to decompose the matrix back into these two
components.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You must set the <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code> when using Robust PCA.</p>
</div>
<p>The default RPCA algorithm is GoDec <a class="reference internal" href="bibliography.html#zhou2011"><span class="std std-ref">[Zhou2011]</span></a>. In HyperSpy
it returns the factors and loadings of <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/>. RPCA solvers work by using
regularization, in a similar manner to lasso or ridge regression, to enforce
the low-rank constraint on the data. The low-rank regularization parameter,
<code class="docutils literal notranslate"><span class="pre">lambda1</span></code>, defaults to <code class="docutils literal notranslate"><span class="pre">1/sqrt(n_features)</span></code>, but it is strongly recommended
that you explore the behaviour of different values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;RPCA&quot;</span><span class="p">,</span> <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lambda1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>HyperSpy also implements an <em>online</em> algorithm for RPCA developed by Feng et
al. <a class="reference internal" href="bibliography.html#feng2013"><span class="std std-ref">[Feng2013]</span></a>. This minimizes memory usage, making it
suitable for large datasets, and can often be faster than the default
algorithm.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORPCA&quot;</span><span class="p">,</span> <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>The online RPCA implementation sets several default parameters that are
usually suitable for most datasets, including the regularization parameter
highlighted above. Again, it is strongly recommended that you explore the
behaviour of these parameters. To further improve the convergence, you can
“train” the algorithm with the first few samples of your dataset. For example,
the following code will train ORPCA using the first 32 samples of the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORPCA&quot;</span><span class="p">,</span> <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">training_samples</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, online RPCA includes two alternatives methods to the default
block-coordinate descent solver, which can again improve both the convergence
and speed of the algorithm. These are particularly useful for very large datasets.</p>
<p>The methods are based on stochastic gradient descent (SGD), and take an
additional parameter to set the learning rate. The learning rate dictates
the size of the steps taken by the gradient descent algorithm, and setting
it too large can lead to oscillations that prevent the algorithm from
finding the correct minima. Usually a value between 1 and 2 works well:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORPCA&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;SGD&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">subspace_learning_rate</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also use Momentum Stochastic Gradient Descent (MomentumSGD),
which typically improves the convergence properties of stochastic gradient
descent. This takes the further parameter “momentum”, which should be a
fraction between 0 and 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORPCA&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MomentumSGD&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">subspace_learning_rate</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">subspace_momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Using the “SGD” or “MomentumSGD” methods enables the subspace,
i.e. the underlying low-rank component, to be tracked as it changes
with each sample update. The default method instead assumes a fixed,
static subspace.</p>
</div>
<div class="section" id="non-negative-matrix-factorization-nmf">
<span id="mva-nmf"></span><h3>Non-negative matrix factorization (NMF)<a class="headerlink" href="#non-negative-matrix-factorization-nmf" title="Permalink to this headline">¶</a></h3>
<p>Another popular decomposition method is non-negative matrix factorization
(NMF), which can be accessed in HyperSpy with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;NMF&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Unlike PCA, NMF forces the components to be strictly non-negative, which can
aid the physical interpretation of components for count data such as images,
EELS or EDS. For an example of NMF in EELS processing, see
<a class="reference internal" href="bibliography.html#nicoletti2013"><span class="std std-ref">[Nicoletti2013]</span></a>.</p>
<p>NMF takes the optional argument <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code>, which determines the number
of components to keep. Setting this to a small number is recommended to keep
the computation time small. Often it is useful to run a PCA decomposition first
and use the <a class="reference internal" href="#mva-scree-plot"><span class="std std-ref">scree plot</span></a> to determine a suitable value
for <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code>.</p>
</div>
<div class="section" id="robust-non-negative-matrix-factorization-rnmf">
<span id="mva-rnmf"></span><h3>Robust non-negative matrix factorization (RNMF)<a class="headerlink" href="#robust-non-negative-matrix-factorization-rnmf" title="Permalink to this headline">¶</a></h3>
<p>In a similar manner to the online, robust methods that complement PCA
<a class="reference internal" href="#mva-rpca"><span class="std std-ref">above</span></a>, HyperSpy includes an online robust NMF method.
This is based on the OPGD (Online Proximal Gradient Descent) algorithm
of <a class="reference internal" href="bibliography.html#zhao2016"><span class="std std-ref">[Zhao2016]</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You must set the <code class="docutils literal notranslate"><span class="pre">output_dimension</span></code> when using Robust NMF.</p>
</div>
<p>As before, you can control the regularization applied via the parameter “lambda1”:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORNMF&quot;</span><span class="p">,</span> <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lambda1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>The MomentumSGD method  is useful for scenarios where the subspace, i.e. the
underlying low-rank component, is changing over time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORNMF&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MomentumSGD&quot;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">subspace_learning_rate</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">subspace_momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>Both the default and MomentumSGD solvers assume an <em>l2</em>-norm minimization problem,
which can still be sensitive to <em>very</em> heavily corrupted data. A more robust
alternative is available, although it is typically much slower.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;ORNMF&quot;</span><span class="p">,</span> <span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;RobustPGD&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-decomposition-algorithms">
<span id="mva-custom-decomposition"></span><h3>Custom decomposition algorithms<a class="headerlink" href="#custom-decomposition-algorithms" title="Permalink to this headline">¶</a></h3>
<p>HyperSpy supports passing a custom decomposition algorithm, provided it follows the form of a
<a class="reference external" href="https://scikit-learn.org/stable/developers/develop.html">scikit-learn estimator</a>.
Any object that implements <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">transform()</span></code> methods is acceptable, including
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a> and <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a>.
You can access the fitted estimator by passing <code class="docutils literal notranslate"><span class="pre">return_info=True</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Passing a custom decomposition algorithm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s2">&quot;PCA&quot;</span><span class="p">,</span> <span class="n">PCA</span><span class="p">())])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span> <span class="n">return_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">Pipeline(memory=None,</span>
<span class="go">         steps=[(&#39;scaler&#39;, MinMaxScaler(copy=True, feature_range=(0, 1))),</span>
<span class="go">                (&#39;PCA&#39;, PCA(copy=True, iterated_power=&#39;auto&#39;, n_components=None,</span>
<span class="go">                            random_state=None, svd_solver=&#39;auto&#39;, tol=0.0,</span>
<span class="go">                            whiten=False))],</span>
<span class="go">         verbose=False)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="blind-source-separation">
<span id="mva-blind-source-separation"></span><h2>Blind Source Separation<a class="headerlink" href="#blind-source-separation" title="Permalink to this headline">¶</a></h2>
<p>In some cases it is possible to obtain more physically interpretable set of
components using a process called Blind Source Separation (BSS). This largely
depends on the particular application. For more information about blind source
separation please see <a class="reference internal" href="bibliography.html#hyvarinen2000"><span class="std std-ref">[Hyvarinen2000]</span></a>, and for an
example application to EELS analysis, see <a class="reference internal" href="bibliography.html#pena2010"><span class="std std-ref">[Pena2010]</span></a>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The BSS algorithms operate on the result of a previous
decomposition analysis. It is therefore necessary to perform a
<a class="reference internal" href="#mva-decomposition"><span class="std std-ref">decomposition</span></a> first before calling
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.blind_source_separation" title="hyperspy.learn.mva.MVA.blind_source_separation"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blind_source_separation()</span></code></a>, otherwise it
will raise an error.</p>
<p>You must provide an integer <code class="docutils literal notranslate"><span class="pre">number_of_components</span></code> argument,
or a list of components as the <code class="docutils literal notranslate"><span class="pre">comp_list</span></code> argument. This performs
BSS on the chosen number/list of components from the previous
decomposition.</p>
</div>
<p>To perform blind source separation on the result of a previous decomposition,
run the <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.blind_source_separation" title="hyperspy.learn.mva.MVA.blind_source_separation"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blind_source_separation()</span></code></a> method, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hyperspy.signals</span> <span class="kn">import</span> <span class="n">Signal1D</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">Signal1D</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">blind_source_separation</span><span class="p">(</span><span class="n">number_of_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="go"># Perform only on the first and third components</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">blind_source_separation</span><span class="p">(</span><span class="n">comp_list</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<div class="section" id="id1">
<h3>Available algorithms<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>HyperSpy implements a number of BSS algorithms via the <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> argument.
The table below lists the algorithms that are currently available, and includes
links to the appropriate documentation for more information on each one.</p>
<span id="bss-table"></span><table class="docutils align-default" id="id8">
<caption><span class="caption-text">Available blind source separation algorithms in HyperSpy</span><a class="headerlink" href="#id8" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 31%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Algorithm</p></th>
<th class="head"><p>Method</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>“sklearn_fastica” (default)</p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html#sklearn.decomposition.FastICA" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.decomposition.FastICA</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>“orthomax”</p></td>
<td><p><a class="reference internal" href="../api/hyperspy.learn.orthomax.html#hyperspy.learn.orthomax.orthomax" title="hyperspy.learn.orthomax.orthomax"><code class="xref py py-func docutils literal notranslate"><span class="pre">orthomax()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p>“FastICA”</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mdp.nodes.FastICANode</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“JADE”</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mdp.nodes.JADENode</span></code></p></td>
</tr>
<tr class="row-even"><td><p>“CuBICA”</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mdp.nodes.CuBICANode</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>“TDSEP”</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mdp.nodes.TDSEPNode</span></code></p></td>
</tr>
<tr class="row-even"><td><p>custom object</p></td>
<td><p>An object implementing  <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and  <code class="docutils literal notranslate"><span class="pre">transform()</span></code> methods</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Except <a class="reference internal" href="../api/hyperspy.learn.orthomax.html#hyperspy.learn.orthomax.orthomax" title="hyperspy.learn.orthomax.orthomax"><code class="xref py py-func docutils literal notranslate"><span class="pre">orthomax()</span></code></a>, all of the implemented BSS algorithms listed above
rely on external packages being available on your system. <code class="docutils literal notranslate"><span class="pre">sklearn_fastica</span></code>, requires
<a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> while <code class="docutils literal notranslate"><span class="pre">FastICA,</span> <span class="pre">JADE,</span> <span class="pre">CuBICA,</span> <span class="pre">TDSEP</span></code>
require the <a class="reference external" href="http://mdp-toolkit.sourceforge.net/">Modular toolkit for Data Processing (MDP)</a>.</p>
</div>
</div>
<div class="section" id="orthomax">
<span id="mva-orthomax"></span><h3>Orthomax<a class="headerlink" href="#orthomax" title="Permalink to this headline">¶</a></h3>
<p>Orthomax rotations are a statistical technique used to clarify and highlight the relationship among factors,
by adjusting the coordinates of PCA results. The most common approach is known as
<a class="reference external" href="https://en.wikipedia.org/wiki/Varimax_rotation">“varimax”</a>, which intended to maximize the variance shared
among the components while preserving orthogonality. The results of an orthomax rotation following PCA are
often “simpler” to interpret than just PCA, since each componenthas a more discrete contribution to the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hyperspy.signals</span> <span class="kn">import</span> <span class="n">Signal1D</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">Signal1D</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">(</span><span class="n">output_dimension</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">blind_source_separation</span><span class="p">(</span><span class="n">number_of_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;orthomax&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="independent-component-analysis-ica">
<span id="mva-ica"></span><h3>Independent component analysis (ICA)<a class="headerlink" href="#independent-component-analysis-ica" title="Permalink to this headline">¶</a></h3>
<p>One of the most common approaches for blind source separation is
<a class="reference external" href="https://en.wikipedia.org/wiki/Independent_component_analysis">Independent Component Analysis (ICA)</a>.
This separates a signal into subcomponents by assuming that the subcomponents are (a) non-Gaussian,
and (b) that they are statistically independent from each other.</p>
</div>
<div class="section" id="custom-bss-algorithms">
<span id="mva-custom-bss"></span><h3>Custom BSS algorithms<a class="headerlink" href="#custom-bss-algorithms" title="Permalink to this headline">¶</a></h3>
<p>As with <a class="reference internal" href="#mva-decomposition"><span class="std std-ref">decomposition</span></a>, HyperSpy supports passing a custom BSS algorithm,
provided it follows the form of a <a class="reference external" href="https://scikit-learn.org/stable/developers/develop.html">scikit-learn estimator</a>.
Any object that implements <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">transform()</span></code> methods is acceptable, including
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a> and <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a>.
You can access the fitted estimator by passing <code class="docutils literal notranslate"><span class="pre">return_info=True</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Passing a custom BSS algorithm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">FastICA</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s2">&quot;ica&quot;</span><span class="p">,</span> <span class="n">FastICA</span><span class="p">())])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">blind_source_separation</span><span class="p">(</span><span class="n">number_of_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span> <span class="n">return_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span>
<span class="go">Pipeline(memory=None,</span>
<span class="go">         steps=[(&#39;scaler&#39;, MinMaxScaler(copy=True, feature_range=(0, 1))),</span>
<span class="go">                (&#39;ica&#39;, FastICA(algorithm=&#39;parallel&#39;, fun=&#39;logcosh&#39;, fun_args=None,</span>
<span class="go">                                max_iter=200, n_components=3, random_state=None,</span>
<span class="go">                                tol=0.0001, w_init=None, whiten=True))],</span>
<span class="go">         verbose=False)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="cluster-analysis">
<span id="cluster-analysis-label"></span><h2>Cluster analysis<a class="headerlink" href="#cluster-analysis" title="Permalink to this headline">¶</a></h2>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.6.</span></p>
</div>
<div class="section" id="id5">
<h3>Introduction<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Cluster_analysis">Cluster analysis</a> or clustering
is the task of grouping a set of measurements such that measurements in the same
group (called a cluster) are more similar (in some sense) to each other than to
those in other groups (clusters).
A HyperSpy signal can represent a number of large arrays of different measurements
which can represent spectra, images or sets of paramaters.
Identifying and extracting trends from large datasets is often difficult and
decomposition methods, blind source separation and cluster analysis play an important role in this process.</p>
<p>Cluster analysis, in essence, compares the “distances” (or similar metric)
between different sets of measurements and groups those that are closest together.
The features it groups can be raw data points, for example, comparing for
every navigation dimension all points of a spectrum. However, if the
dataset is large, the process of clustering can be computationally intensive so
clustering is more commonly used on an extracted set of features or parameters.
For example, extraction of two peak positions of interest via a fitting process
rather than clustering all spectra points.</p>
<p>In favourable cases, matrix decomposition and related methods can decompose the
data into a (ideally small) set of significant loadings and factors.
The factors capture a core representation of the features in the data and the loadings
provide the mixing ratios of these factors that best describe the original data.
Overall, this usually represents a much smaller data volume compared to the original data
and can helps to identify correlations.</p>
<p>A detailed description of the application of cluster analysis in x-ray
spectro-microscopy and further details on the theory and implementation can
be found in <a class="reference internal" href="bibliography.html#lerotic2004"><span class="std std-ref">[Lerotic2004]</span></a>.</p>
</div>
<div class="section" id="nomenclature">
<h3>Nomenclature<a class="headerlink" href="#nomenclature" title="Permalink to this headline">¶</a></h3>
<p>Taking the example of a 1D Signal of dimensions <code class="docutils literal notranslate"><span class="pre">(20,</span> <span class="pre">10|4)</span></code> containing the
dataset, we say there are 200 <em>samples</em>. The four measured parameters are the
<em>features</em>. If we choose to search for 3 clusters within this dataset, we
derive three main values:</p>
<ol class="arabic simple">
<li><p>The <cite>labels</cite>, of dimensions <code class="docutils literal notranslate"><span class="pre">(3|</span> <span class="pre">20,</span> <span class="pre">10)</span></code>. Each navigation position is
assigned to a cluster. The <cite>labels</cite> of each cluster are boolean arrays
that mark the data that has been assigned to the cluster with <cite>True</cite>.</p></li>
<li><p>The <cite>cluster_distances</cite>, of dimensions <code class="docutils literal notranslate"><span class="pre">(3|</span> <span class="pre">20,</span> <span class="pre">10)</span></code>, which are the
distances of all the data points to the centroid of each cluster.</p></li>
<li><p>The “<em>cluster signals</em>”, which are signals that are representative of
their clusters. In HyperSpy two are computer:
<cite>cluster_sum_signals</cite> and <cite>cluster_centroid_signals</cite>,
of dimensions <code class="docutils literal notranslate"><span class="pre">(3|</span> <span class="pre">4)</span></code>, which are the sum of all the cluster signals
that belong to each cluster or the signal closest to each cluster
centroid respectively.</p></li>
</ol>
</div>
<div class="section" id="clustering-functions-hyperspy">
<h3>Clustering functions HyperSpy<a class="headerlink" href="#clustering-functions-hyperspy" title="Permalink to this headline">¶</a></h3>
<p>All HyperSpy signals have the following methods for clustering analysis:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.cluster_analysis" title="hyperspy.learn.mva.MVA.cluster_analysis"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cluster_analysis()</span></code></a></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_results()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_labels()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_signals()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_distances()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_cluster_signals()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_cluster_labels()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_cluster_distances()</span></code></p></li>
<li><p><a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.estimate_number_of_clusters" title="hyperspy.learn.mva.MVA.estimate_number_of_clusters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">estimate_number_of_clusters()</span></code></a></p></li>
<li><p><a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.plot_cluster_metric" title="hyperspy.learn.mva.MVA.plot_cluster_metric"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_metric()</span></code></a></p></li>
</ul>
<p>The <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.cluster_analysis" title="hyperspy.learn.mva.MVA.cluster_analysis"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cluster_analysis()</span></code></a> method can perform cluster
analysis using any <a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html">sklearn.clustering</a> clustering
algorithms or any other object with a compatible API. This involves importing
the relevant algorithm class from scikit-learn.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">cluster_analysis</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="s2">&quot;signal&quot;</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
<p>For convenience, the default algorithm is <code class="docutils literal notranslate"><span class="pre">kmeans</span></code> algorithm and is imported
internally. All extra keyword arguments are passed to the algorithm when
present. Therefore the following code is equivalent to the previous one:</p>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">cluster_analysis</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="s2">&quot;signal&quot;</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
<p>is equivalent to:</p>
<p><a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.cluster_analysis" title="hyperspy.learn.mva.MVA.cluster_analysis"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cluster_analysis()</span></code></a> computes the cluster labels. The
clusters areas with identical label are averaged to create a set of cluster
centres. This averaging can be performed on the <code class="docutils literal notranslate"><span class="pre">signal</span></code> itself, the
<code class="docutils literal notranslate"><span class="pre">bss</span></code> or <code class="docutils literal notranslate"><span class="pre">decomposition</span></code> results or a user supplied signal.</p>
</div>
<div class="section" id="pre-processing">
<h3>Pre-processing<a class="headerlink" href="#pre-processing" title="Permalink to this headline">¶</a></h3>
<p>Cluster analysis measures the distances between features and groups them. It
is often necessary to pre-process the features in order to obtain meaningful
results.</p>
<p>For example, pre-processing can be useful to reveal clusters when
performing cluster analysis of decomposition results. Decomposition methods
decompose data into a set of factors and a set of loadings defining the
mixing needed to represent the data. If signal 1 is reduced to three
components with mixing 0.1 0.5 2.0, and signal 2 is reduced to a mixing of 0.2
1.0 4.0, it should be clear that these represent the same signal but with a
scaling difference. Normalization of the data can again be used to remove
scaling effects.</p>
<p>Therefore, the pre-processing step
will highly influence the results and should be evaluated for the problem
under investigation.</p>
<p>All pre-processing methods from (or compatible with) <a class="reference external" href="https://scikit-learn.org/stable/modules/preprocessing.html">sklearn.preprocessing</a> can be passed
to the <code class="docutils literal notranslate"><span class="pre">scaling</span></code> keyword of the <a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.cluster_analysis" title="hyperspy.learn.mva.MVA.cluster_analysis"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cluster_analysis()</span></code></a>
method. For convenience, the following methods from scikit-learn are
available as standard: <code class="docutils literal notranslate"><span class="pre">standard</span></code> , <code class="docutils literal notranslate"><span class="pre">minmax</span></code> and <code class="docutils literal notranslate"><span class="pre">norm</span></code> as
standard. Briefly, <code class="docutils literal notranslate"><span class="pre">norm</span></code> treats the features as a vector and normalizes the
vector length. <code class="docutils literal notranslate"><span class="pre">standard</span></code> re-scales each feature by removing the mean and
scaling to unit variance. <code class="docutils literal notranslate"><span class="pre">minmax</span></code> normalizes each feature between the
minimum and maximum range of that feature.</p>
<div class="section" id="cluster-signals">
<h4>Cluster signals<a class="headerlink" href="#cluster-signals" title="Permalink to this headline">¶</a></h4>
<p>In HyperSpy <em>cluster signals</em> are signals that somehow represent their clusters.
The concept is ill-defined, since cluster algorithms only assign data points to
clusters. HyperSpy computers 2 cluster signals,</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_sum_signals</span></code>, which are the sum of all the cluster signals
that belong to each cluster.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cluster_centroid_signals</span></code>, which is the signal closest to each cluster
centroid.</p></li>
</ol>
<p>When plotting the “<em>cluster signals</em>” we can select any of those
above using the <code class="docutils literal notranslate"><span class="pre">signal</span></code> keyword argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_labels</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="s2">&quot;centroid&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In addition, it is possible to plot the mean signal over the different
clusters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_labels</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="clustering-with-user-defined-algorithms">
<h4>Clustering with user defined algorithms<a class="headerlink" href="#clustering-with-user-defined-algorithms" title="Permalink to this headline">¶</a></h4>
<p>User developed preprocessing or cluster algorithms can be
used in place of the sklearn methods.
A preprocessing object needs a <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> which
appropriately scales the data.
The example below defines a preprocessing class which normalizes
the data then applies a square root to enhances weaker features.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">PowerScaling</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">power</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">scaled_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">/</span><span class="n">norm</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">scaled_data</span> <span class="o">=</span> <span class="n">scaled_data</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">)</span><span class="o">+</span><span class="mf">1.0e-8</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">scaled_data</span> <span class="o">=</span> <span class="n">scaled_data</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">scaled_data</span>
</pre></div>
</div>
<p>The PowerScaling class can then be passed to the cluster_analysis method for use.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span> <span class="o">=</span> <span class="n">PowerScaling</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">cluster_analysis</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="s2">&quot;decomposition&quot;</span><span class="p">,</span> <span class="n">number_of_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">=</span><span class="n">ps</span><span class="p">)</span>
</pre></div>
</div>
<p>For user defined clustering algorithms the class must implementation
<code class="docutils literal notranslate"><span class="pre">fit</span></code> and have a <code class="docutils literal notranslate"><span class="pre">label_</span></code> attribute that contains the clustering labels.
An example template would be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyClustering</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span> <span class="o">=</span> <span class="kc">None</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">fit_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span> <span class="o">=</span> <span class="n">do_something</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<div class="section" id="clustering-using-decomposition-results">
<h4>Clustering using decomposition results<a class="headerlink" href="#clustering-using-decomposition-results" title="Permalink to this headline">¶</a></h4>
<p>Let’s use the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html">make_blobs</a>
function supplied by <cite>scikit-learn</cite> to make dummy data to see how clustering
might work in practice.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">hyperspy.api</span> <span class="k">as</span> <span class="nn">hs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">Signal1D</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hs</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">plot_images</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/clustering_data.png" src="../_images/clustering_data.png" />
<p>To see how cluster analysis works it’s best to first examine the signal.
Moving around the image you should be able to see 3 distinct regions in which
the 1D signal modulates slightly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s perform SVD to reduce the dimensionality of the dataset by exploiting
redundancies:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">decomposition</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_explained_variance_ratio</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/clustering_scree_plot.png" src="../_images/clustering_scree_plot.png" />
<p>From the scree plot we deduce that, as expected, that the dataset can be reduce
to 3 components. Let’s plot their loadings:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_decomposition_loadings</span><span class="p">(</span><span class="n">comp_ids</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">axes_decor</span><span class="o">=</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/clustering_decomposition_loadings.png" src="../_images/clustering_decomposition_loadings.png" />
<p>In the SVD loading we can identify 3 regions, but they are mixed in the components.
Let’s perform cluster analysis of decomposition results, to find similar regions
and the representative features in those regions. Notice that this dataset does
not require any pre-processing for cluster analysis.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">cluster_analysis</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="s2">&quot;decomposition&quot;</span><span class="p">,</span> <span class="n">number_of_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_labels</span><span class="p">(</span><span class="n">axes_decor</span><span class="o">=</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/clustering_labels.png" src="../_images/clustering_labels.png" />
<p>To see what the labels the cluster algorithm has assigned you can inspect
the <code class="docutils literal notranslate"><span class="pre">cluster_labels</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">learning_results</span><span class="o">.</span><span class="n">cluster_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,</span>
<span class="go">   1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">   0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</span>
</pre></div>
</div>
<p>In this case we know there are 3 cluster, but for real examples the number of
clusters is not known <em>a priori</em>. A number of metrics, such as elbow,
Silhouette and Gap can be used to estimate the optimal number of clusters.
The elbow method measures the sum-of-squares of the distances within a
cluster and, as for the PCA decomposition, an “elbow” or point where the gains
diminish with increasing number of clusters indicates the ideal number of
clusters. Silhouette analysis measures how well separated clusters are and
can be used to determine the most likely number of clusters. As the scoring
is a measure of separation of clusters a number of solutions may occur and
maxima in the scores are used to indicate possible solutions. Gap analysis
is similar but compares the “gap” between the clustered data results and
those from a randomly data set of the same size. The largest gap indicates
the best clustering. The metric results can be plotted to check how
well-defined the clustering is.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">estimate_number_of_clusters</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="s2">&quot;decomposition&quot;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;gap&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_metric</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/clustering_Gap.png" src="../_images/clustering_Gap.png" />
<p>The optimal number of clusters can be set or accessed from the learning
results</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">learning_results</span><span class="o">.</span><span class="n">number_of_clusters</span>
<span class="go">3</span>
</pre></div>
</div>
</div>
<div class="section" id="clustering-using-another-signal-as-source">
<h4>Clustering using another signal as source<a class="headerlink" href="#clustering-using-another-signal-as-source" title="Permalink to this headline">¶</a></h4>
<p>In this example we will perform clustering analysis on the position of two
peaks. The signals containing the position of the peaks can be computed for
example using <a class="reference internal" href="model.html#model-label"><span class="std std-ref">curve fitting</span></a>. Given an existing fitted
model, the parameters can be extracted as signals and stacked. Clustering can
then be applied as described previously to identify trends in the fitted
results.</p>
<p>Let’s start by creating a suitable synthetic dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">hyperspy.api</span> <span class="k">as</span> <span class="nn">hs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_dummy</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">signals</span><span class="o">.</span><span class="n">Signal1D</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_dummy</span><span class="o">.</span><span class="n">axes_manager</span><span class="o">.</span><span class="n">signal_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">2e-3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_dummy</span><span class="o">.</span><span class="n">axes_manager</span><span class="o">.</span><span class="n">signal_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="s2">&quot;eV&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_dummy</span><span class="o">.</span><span class="n">axes_manager</span><span class="o">.</span><span class="n">signal_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;energy&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">s_dummy</span><span class="o">.</span><span class="n">create_model</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components1D</span><span class="o">.</span><span class="n">GaussianHF</span><span class="p">(</span><span class="n">fwhm</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hs</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">components1D</span><span class="o">.</span><span class="n">GaussianHF</span><span class="p">(</span><span class="n">fwhm</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:</span><span class="mi">32</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">.</span><span class="mi">3</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][</span><span class="mi">32</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">.</span><span class="mi">7</span> <span class="o">+</span> <span class="o">.</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF_0</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:,</span> <span class="mi">32</span><span class="p">:]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:,</span> <span class="mi">32</span><span class="p">:]</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF_0</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">32</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">32</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">m</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">component</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;is_set&quot;</span><span class="p">][:]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">... </span>    <span class="n">component</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">map</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">][:]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">as_signal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">as_signal</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hs</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">plot_images</span><span class="p">(</span><span class="n">stack</span><span class="p">,</span> <span class="n">axes_decor</span><span class="o">=</span><span class="s2">&quot;off&quot;</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="s2">&quot;single&quot;</span><span class="p">,</span>
<span class="go">suptitle=&quot;&quot;)</span>
</pre></div>
</div>
<img alt="../_images/clustering_gaussian_centres.png" src="../_images/clustering_gaussian_centres.png" />
<p>Let’s now perform cluster analysis on the stack and calculate the centres using
the spectrum image. Notice that we don’t need to fit the model to the data
because this is a synthetic dataset. When analysing experimental data you will
need to fit the model first. Also notice that here we need to pre-process the
dataset by normalization in order to reveal the clusters due to the
proportionality relationship between the position of the peaks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stack</span> <span class="o">=</span> <span class="n">hs</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">GaussianHF</span><span class="o">.</span><span class="n">centre</span><span class="o">.</span><span class="n">as_signal</span><span class="p">(),</span>
<span class="go">m.components.GaussianHF_0.centre.as_signal()])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">estimate_number_of_clusters</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="n">stack</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">)</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">cluster_analysis</span><span class="p">(</span><span class="n">cluster_source</span><span class="o">=</span><span class="n">stack</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">source_for_centers</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_labels</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/clustering_gaussian_centres_labels.png" src="../_images/clustering_gaussian_centres_labels.png" />
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_signals</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/clustering_gaussian_centres_mean.png" src="../_images/clustering_gaussian_centres_mean.png" />
<p>Notice that in this case averaging or summing the signals of
each cluster is not appropriate, since the clustering criterium
is the ratio between the peaks positions. A better alternative
is to plot the signals closest to the centroids:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_cluster_signals</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="s2">&quot;centroid&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/clustering_gaussian_centres_centroid.png" src="../_images/clustering_gaussian_centres_centroid.png" />
</div>
</div>
</div>
<div class="section" id="visualizing-results">
<span id="mva-visualization"></span><h2>Visualizing results<a class="headerlink" href="#visualizing-results" title="Permalink to this headline">¶</a></h2>
<p>HyperSpy includes a number of plotting methods for visualizing the results
of decomposition and blind source separation analyses. All the methods
begin with <code class="docutils literal notranslate"><span class="pre">plot_</span></code>.</p>
<div class="section" id="scree-plots">
<span id="mva-scree-plot"></span><h3>Scree plots<a class="headerlink" href="#scree-plots" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Scree plots are only available for the <code class="docutils literal notranslate"><span class="pre">&quot;SVD&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;PCA&quot;</span></code> algorithms.</p>
</div>
<p>PCA will sort the components in the dataset in order of decreasing
variance. It is often useful to estimate the dimensionality of the data by
plotting the explained variance against the component index. This plot is
sometimes called a scree plot. For most datasets, the values in a scree plot
will decay rapidly, eventually becoming a slowly descending line.</p>
<p>To obtain a scree plot for your dataset, run the
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.plot_explained_variance_ratio" title="hyperspy.learn.mva.MVA.plot_explained_variance_ratio"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_explained_variance_ratio()</span></code></a> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_explained_variance_ratio</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center" id="id9">
<a class="reference internal image-reference" href="../_images/screeplot.png"><img alt="../_images/screeplot.png" src="../_images/screeplot.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">PCA scree plot</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<p>The point at which the scree plot becomes linear (often referred to as
the “elbow”) is generally judged to be a good estimation of the dimensionality
of the data (or equivalently, the number of components that should be retained
- see below). Components to the left of the elbow are considered part of the “signal”,
while components to the right are considered to be “noise”, and thus do not explain
any significant features of the data.</p>
<p>By specifying a <code class="docutils literal notranslate"><span class="pre">threshold</span></code> value, a cutoff line will be drawn at the total variance
specified, and the components above this value will be styled distinctly from the
remaining components to show which are considered signal, as opposed to noise.
Alternatively, by providing an integer value for <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, the line will
be drawn at the specified component (see below).</p>
<p>Note that in the above scree plot, the first component has index 0. This is because
Python uses zero-based indexing. To switch to a “number-based” (rather than
“index-based”) notation, specify the <code class="docutils literal notranslate"><span class="pre">xaxis_type</span></code> parameter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">plot_explained_variance_ratio</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">xaxis_type</span><span class="o">=</span><span class="s1">&#39;number&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center" id="id10">
<a class="reference internal image-reference" href="../_images/screeplot2.png"><img alt="../_images/screeplot2.png" src="../_images/screeplot2.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">PCA scree plot with number-based axis labeling and a threshold value
specified</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
<p>The number of significant components can be estimated and a vertical line
drawn to represent this by specifying <code class="docutils literal notranslate"><span class="pre">vline=True</span></code>. In this case, the “elbow”
is found in the variance plot by estimating the distance from each point in the
variance plot to a line joining the first and last points of the plot, and then
selecting the point where this distance is largest.</p>
<p>If multiple maxima are found, the index corresponding to the first occurrence
is returned. As the index of the first component is zero, the number of
significant PCA components is the elbow index position + 1. More details
about the elbow-finding technique can be found in
<a class="reference internal" href="bibliography.html#satopaa2011"><span class="std std-ref">[Satopää2011]</span></a>, and in the documentation for
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.estimate_elbow_position" title="hyperspy.learn.mva.MVA.estimate_elbow_position"><code class="xref py py-meth docutils literal notranslate"><span class="pre">estimate_elbow_position()</span></code></a>.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/screeplot_elbow_method.png"><img alt="../_images/screeplot_elbow_method.png" src="../_images/screeplot_elbow_method.png" style="width: 500px;" /></a>
</div>
<div class="figure align-center" id="id11">
<a class="reference internal image-reference" href="../_images/screeplot3.png"><img alt="../_images/screeplot3.png" src="../_images/screeplot3.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">PCA scree plot with number-based axis labeling and an estimate of the no of significant
positions based on the “elbow” position</span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
<p>These options (together with many others), can be customized to
develop a figure of your liking. See the documentation of
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.plot_explained_variance_ratio" title="hyperspy.learn.mva.MVA.plot_explained_variance_ratio"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_explained_variance_ratio()</span></code></a> for more details.</p>
<p>Sometimes it can be useful to get the explained variance ratio as a spectrum.
For example, to plot several scree plots obtained with
different data pre-treatments in the same figure, you can combine
<a class="reference internal" href="../api/hyperspy.drawing.utils.html#hyperspy.drawing.utils.plot_spectra" title="hyperspy.drawing.utils.plot_spectra"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_spectra()</span></code></a> with
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.MVA.get_explained_variance_ratio" title="hyperspy.learn.mva.MVA.get_explained_variance_ratio"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_explained_variance_ratio()</span></code></a>.</p>
</div>
<div class="section" id="decomposition-plots">
<span id="mva-plot-decomposition"></span><h3>Decomposition plots<a class="headerlink" href="#decomposition-plots" title="Permalink to this headline">¶</a></h3>
<p>HyperSpy provides a number of methods for visualizing the factors and loadings
found by a decomposition analysis. To plot everything in a compact form,
use <code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_decomposition_results()</span></code>.</p>
<p>You can also plot the factors and loadings separately using the following
methods. It is recommended that you provide the number of factors or loadings
you wish to visualise, since the default is to plot all of them.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_decomposition_factors()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_decomposition_loadings()</span></code></p></li>
</ul>
</div>
<div class="section" id="blind-source-separation-plots">
<span id="mva-plot-bss"></span><h3>Blind source separation plots<a class="headerlink" href="#blind-source-separation-plots" title="Permalink to this headline">¶</a></h3>
<p>Visualizing blind source separation results is much the same as decomposition.
You can use <code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_bss_results()</span></code> for a compact display,
or instead:</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_bss_factors()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_bss_loadings()</span></code></p></li>
</ul>
</div>
<div class="section" id="clustering-plots">
<span id="mva-get-results"></span><h3>Clustering plots<a class="headerlink" href="#clustering-plots" title="Permalink to this headline">¶</a></h3>
<p>Visualizing cluster results is much the same as decomposition.
You can use <code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_bss_results()</span></code> for a compact display,
or instead:</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_results()</span></code>.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_signals()</span></code>.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_cluster_labels()</span></code>.</p></li>
</ul>
</div>
</div>
<div class="section" id="obtaining-the-results-as-basesignal-instances">
<h2>Obtaining the results as BaseSignal instances<a class="headerlink" href="#obtaining-the-results-as-basesignal-instances" title="Permalink to this headline">¶</a></h2>
<p>The decomposition and BSS results are internally stored as numpy arrays in the
<a class="reference internal" href="../api/hyperspy.signal.html#hyperspy.signal.BaseSignal" title="hyperspy.signal.BaseSignal"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseSignal</span></code></a> class. Frequently it is useful to obtain the
decomposition/BSS factors and loadings as HyperSpy signals, and HyperSpy
provides the following methods for that purpose:</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_decomposition_loadings()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_decomposition_factors()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_bss_loadings()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_bss_factors()</span></code></p></li>
</ul>
</div>
<div class="section" id="saving-and-loading-results">
<span id="mva-saving-label"></span><h2>Saving and loading results<a class="headerlink" href="#saving-and-loading-results" title="Permalink to this headline">¶</a></h2>
<div class="section" id="saving-in-the-main-file">
<h3>Saving in the main file<a class="headerlink" href="#saving-in-the-main-file" title="Permalink to this headline">¶</a></h3>
<p>If you save the dataset on which you’ve performed machine learning analysis in
the <a class="reference internal" href="io.html#hspy-format"><span class="std std-ref">HSpy - HyperSpy’s HDF5 Specification</span></a> format (the default in HyperSpy) (see
<a class="reference internal" href="io.html#saving-files"><span class="std std-ref">Saving data to files</span></a>), the result of the analysis is also saved in the same
file automatically, and it is loaded along with the rest of the data when you
next open the file.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This approach currently supports storing one decomposition and one BSS
result, which may not be enough for your purposes.</p>
</div>
</div>
<div class="section" id="saving-to-an-external-file">
<h3>Saving to an external file<a class="headerlink" href="#saving-to-an-external-file" title="Permalink to this headline">¶</a></h3>
<p>Alternatively, you can save the results of the current machine learning
analysis to a separate file with the
<a class="reference internal" href="../api/hyperspy.learn.mva.html#hyperspy.learn.mva.LearningResults.save" title="hyperspy.learn.mva.LearningResults.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save the result of the analysis</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">learning_results</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_results.npz&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load back the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">learning_results</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;my_results.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="exporting-in-different-formats">
<h3>Exporting in different formats<a class="headerlink" href="#exporting-in-different-formats" title="Permalink to this headline">¶</a></h3>
<p>You can also export the results of a machine learning analysis to any format
supported by HyperSpy with the following methods:</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">export_decomposition_results()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">export_bss_results()</span></code></p></li>
</ul>
<p>These methods accept many arguments to customise the way in which the
data is exported, so please consult the method documentation. The options
include the choice of file format, the prefixes for loadings and factors,
saving figures instead of data and more.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Data exported in this way cannot be easily loaded into HyperSpy’s
machine learning structure.</p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="model.html" class="btn btn-neutral float-right" title="Model fitting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="visualisation.html" class="btn btn-neutral float-left" title="Data visualization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2011-2021, The HyperSpy development team.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>